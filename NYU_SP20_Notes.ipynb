{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NYU-SP20-Notes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9mgUrO9WcC0uvMFEbx4fo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoyEHamlin/NYU-DL-SP20/blob/main/NYU_SP20_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Deep Learning\n",
        "* Youtube List: https://www.youtube.com/playlist?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq\n",
        "* Class Site: https://atcold.github.io/pytorch-Deep-Learning/\n",
        "* Google Drive: https://bitly.com/DLSP20\n",
        "* Github: https://github.com/Atcold/pytorch-Deep-Learning\n"
      ],
      "metadata": {
        "id": "ps0qz0RpH14E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 01"
      ],
      "metadata": {
        "id": "--w6balvHsSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wk 01: Lecture: History, motivation, and evolution of Deep Learning\n",
        "https://www.youtube.com/watch?v=0bMe_vCZo30&list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq&index=1\n",
        "> ## Course \n",
        "![Plan 01](https://raw.githubusercontent.com/RoyEHamlin/NYU-DL-SP20/main/plan-01.png \"Plan 1\") \n",
        "![Plan 02](https://raw.githubusercontent.com/RoyEHamlin/NYU-DL-SP20/main/plan-02.png \"Plan 2\") \n",
        "![Plan 03](https://raw.githubusercontent.com/RoyEHamlin/NYU-DL-SP20/main/plan-03.png \"Plan 3\") \n",
        "\n",
        "***** https://youtu.be/0bMe_vCZo30?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq&t=571 *****\n"
      ],
      "metadata": {
        "id": "UxaXRZTgfgpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wk 01: Motivation of Deep Learning, and Its History and Inspiration\n",
        "https://atcold.github.io/pytorch-Deep-Learning/en/week01/01-1/\n",
        "### Supervised Learning\n",
        "#### Perceptron\n",
        "* 2 layer\n",
        "* 1st: fixed weights\n",
        "* 2nd: trainable\n",
        "\n",
        "#### Adaline (cont. pred. values to 'scale' updating feedback.)\n",
        "#### Pattern Recognition & Gradient Decent\n",
        "* before deep learning\n",
        "  * feature extraction\n",
        "  * vector of features then fed to trainable classifier\n",
        "* After deep learning\n",
        "  * 2-stage -> seq. of modules\n",
        "  * modules have tunable paramenters & nonlinearity\n",
        "* e.g. \n",
        "  * ReLU\n",
        "  * NN = weighted sum of components x rows in matrix\n",
        "* Goal of Sup. learning\n",
        "  * paramenter values = minimize the avg. distance/penalty/divergence btwn target & result\n",
        "  * aka __computational gradient__\n",
        "    * SGD : Stochastic Gradient Decent\n",
        "      * (+) fast converging model on very large training set\n",
        "      * (+) better overall generalization \n",
        "#### Gradient by Backpropagation\n",
        "* takes vector (multi-dimentional), NOT scalar inputs\n",
        "* applies to multiple layers\n",
        "* NOTE: assumptions on matrix help to reduce large matrices (e.g. 256x256 = 200,000 valued matrix)\n",
        "#### Visul recognition done hierarchically \n",
        "* Visual process = feet forward model\n"
      ],
      "metadata": {
        "id": "9rnrJcAyebFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wk 01: Evolution and Uses of CNNs and Why Deep Learning\n",
        "https://atcold.github.io/pytorch-Deep-Learning/en/week01/01-2/"
      ],
      "metadata": {
        "id": "nuKGunCeaACG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evolution of CNNS\n",
        "### Deep Learning and Feature Extraction\n",
        "> multilayer networkes work well b/c use compositional structure of _natural_ data (i.e. hierarchical) \n",
        "> ### Mask RCNNs: creating masks for objects w/i an image\n",
        "* creating masks for each obj. in an image\n",
        "* <u>instance segmentation:</u> # of instances of an obj. in an image.\n",
        "> ### CNN uses \n",
        "* autonomous driving\n",
        "* nalysis of medical images\n",
        "> ### Unansered questions\n",
        "* why multi lyers perform better?\n",
        "* why do CNN do well w/ __natural__ data sets\n",
        "  * speech\n",
        "  * images\n",
        "  * text\n",
        "* how do non-convex optimize so well?\n",
        "* Why do over-parametrised architectures work? \n",
        "> ### common feature extraction approaches\n",
        "* space tilting\n",
        "* random projections\n",
        "* polynomial classiers (feature cross-products)\n",
        "* radial bias functions\n",
        "* kernel machines\n",
        "### Learning representations\n",
        "> ### What is \"deep\"?\n",
        "* deep ≠ 2 layers\n",
        "* deep ≠ every layer sees all raw features\n",
        "* deep = multi layers used to build a <u>hierarchy of features of inc. complexity</u>\n"
      ],
      "metadata": {
        "id": "iNF_dLZHaG9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wekk 02 "
      ],
      "metadata": {
        "id": "KJlRQafTe3PO"
      }
    }
  ]
}